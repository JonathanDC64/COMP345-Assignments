\hypertarget{classabstract__tokenizer}{}\section{abstract\+\_\+tokenizer$<$ T $>$ Class Template Reference}
\label{classabstract__tokenizer}\index{abstract\+\_\+tokenizer$<$ T $>$@{abstract\+\_\+tokenizer$<$ T $>$}}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual std\+::vector$<$ T $>$ \hyperlink{classabstract__tokenizer_a5948210e787d9ed3681800b4e3926701}{tokenize} (const \hyperlink{classdocument}{document} \&doc) const =0
\end{DoxyCompactItemize}
\subsection*{Friends}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classabstract__tokenizer_a061c101e49ebd7f5acfdd596427e2276}\label{classabstract__tokenizer_a061c101e49ebd7f5acfdd596427e2276}} 
std\+::ostream \& {\bfseries operator$<$$<$} (std\+::ostream \&os, const \hyperlink{classabstract__tokenizer}{abstract\+\_\+tokenizer}$<$ T $>$ \&right)
\end{DoxyCompactItemize}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classabstract__tokenizer_a5948210e787d9ed3681800b4e3926701}\label{classabstract__tokenizer_a5948210e787d9ed3681800b4e3926701}} 
\index{abstract\+\_\+tokenizer@{abstract\+\_\+tokenizer}!tokenize@{tokenize}}
\index{tokenize@{tokenize}!abstract\+\_\+tokenizer@{abstract\+\_\+tokenizer}}
\subsubsection{\texorpdfstring{tokenize()}{tokenize()}}
{\footnotesize\ttfamily template$<$typename T$>$ \\
virtual std\+::vector$<$T$>$ \hyperlink{classabstract__tokenizer}{abstract\+\_\+tokenizer}$<$ T $>$\+::tokenize (\begin{DoxyParamCaption}\item[{const \hyperlink{classdocument}{document} \&}]{doc }\end{DoxyParamCaption}) const\hspace{0.3cm}{\ttfamily [pure virtual]}}

splits a document into tokens 

Implemented in \hyperlink{classsentence__tokenizer_a7d8d0af4624c8bc7d37dd85af99f5695}{sentence\+\_\+tokenizer}, and \hyperlink{classword__tokenizer_ab0308f2cf9249f3c296307a055ee78df}{word\+\_\+tokenizer}.



The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
project/abstract\+\_\+tokenizer.\+hpp\end{DoxyCompactItemize}
